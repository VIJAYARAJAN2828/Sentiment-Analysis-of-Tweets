{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c4b047c-ea07-43fb-b164-7003317916f8",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Tweets\n",
    "### Detecting Positive and Negative Sentiments from 1 Million Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba37020b-b831-4c1a-9be8-b131cbd4a39c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82b239c9-2fc4-4e65-9a95-ad3a43c817ce",
   "metadata": {},
   "source": [
    "#### `WHY` should we have to do Sentiment Analysis of Tweets\n",
    "Twitter sentiment analysis is essential for understanding public opinions and trends in real time. \n",
    "\n",
    "It helps businesses improve customer satisfaction, track brand perception, and enhance marketing strategies. \n",
    "\n",
    "Researchers and policymakers can leverage it to analyze societal issues and public sentiment on critical topics.\n",
    "\n",
    "Ultimately, it provides valuable insights for data-driven decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5625b7-4159-45ef-9303-80966574756e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c35d7fb7-4527-44bd-adbe-5b5a0c4fb9ae",
   "metadata": {},
   "source": [
    "#### `Workflow` The process of the Project "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b22d77-56dd-4710-8146-2365e93ff337",
   "metadata": {},
   "source": [
    "<u>Data Preparation</u>\r\n",
    "- Extract the Sentiment140 dataset.\r\n",
    "- Clean and preprocess the text data.\r\n",
    "- Split tweets into individual tokens.\r\n",
    "- Remove common words that do not add meaning.\r\n",
    "- Reduce words to their base or root forms.\r\n",
    "\r\n",
    "<u>Model Training</u>\r\n",
    "- Convert text data to numerical format (e.g., TF-IDF, Bag of Words).\r\n",
    "- Divide the dataset into training and testing subsets.\r\n",
    "- Choose a suitable machine learning model for sentiment classification.\r\n",
    "- Train the model using the training dataset.\r\n",
    "\r\n",
    "<u>Model Evaluation</u>\r\n",
    "- Test the model using the testing dataset and calculate performance metrics.\r\n",
    "- Use the trained model to classify new tweets into positive, negative, or neutal sentiments.\r\n",
    "eniments.  \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1078558b-62ea-4e60-a692-92755f8a7748",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ac8acb2-e005-4e47-aa24-c5812cf6cd85",
   "metadata": {},
   "source": [
    "#### Data Description \n",
    "[ kaggle link](https://www.kaggle.com/datasets/kazanova/sentiment140)\n",
    "\n",
    "- **The Sentiment140 Dataset** contains 1,000,000 tweets extracted using the Twitter API.  \n",
    "- Each tweet is annotated with **sentiment polarity**:\n",
    "  - `0 = Negative sentiment`\n",
    "  - `4 = Positive sentiment`\n",
    "  - `2 = Neutral sentiment` *(rarely present)*.\n",
    "\n",
    "#### Dataset Fields:\n",
    "- **target**: Sentiment polarity of the tweet (0, 2, or 4).\n",
    "- **ids**: Unique identifier for the tweet.\n",
    "- **date**: Timestamp when the tweet was posted.\n",
    "- **flag**: Query used to retrieve the tweet, or `NO_QUERY` if none.\n",
    "- **user**: Username of the person who tweeted.\n",
    "- **text**: The actual tweet content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da013f9-252a-4418-8869-99ceac4dce73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a487d87-d5f0-4fcf-a963-2a81ae4e7191",
   "metadata": {},
   "source": [
    "### 1. Import Nessasary Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d02e461-b7b6-4d20-80c4-a6e7ea233681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0694a3b-0829-47c0-ae56-e8f9ef957515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39f27a77-2711-48b2-8bcc-3c7f0d6f8d01",
   "metadata": {},
   "source": [
    "### 2. Import Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "383a8b14-198d-46cc-9c1b-7c4860731010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1467810369</th>\n",
       "      <th>Mon Apr 06 22:19:45 PDT 2009</th>\n",
       "      <th>NO_QUERY</th>\n",
       "      <th>_TheSpecialOne_</th>\n",
       "      <th>@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811372</td>\n",
       "      <td>Mon Apr 06 22:20:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>joy_wolf</td>\n",
       "      <td>@Kwesidei not the whole crew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599994</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599999 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY  \\\n",
       "0        0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "1        0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "2        0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "3        0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4        0  1467811372  Mon Apr 06 22:20:00 PDT 2009  NO_QUERY   \n",
       "...     ..         ...                           ...       ...   \n",
       "1599994  4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599995  4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996  4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997  4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998  4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "         _TheSpecialOne_  \\\n",
       "0          scotthamilton   \n",
       "1               mattycus   \n",
       "2                ElleCTF   \n",
       "3                 Karoli   \n",
       "4               joy_wolf   \n",
       "...                  ...   \n",
       "1599994  AmandaMarie1028   \n",
       "1599995      TheWDBoards   \n",
       "1599996           bpbabe   \n",
       "1599997     tinydiamondz   \n",
       "1599998   RyanTrevMorris   \n",
       "\n",
       "        @switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  \n",
       "0        is upset that he can't update his Facebook by ...                                                                   \n",
       "1        @Kenichan I dived many times for the ball. Man...                                                                   \n",
       "2          my whole body feels itchy and like its on fire                                                                    \n",
       "3        @nationwideclass no, it's not behaving at all....                                                                   \n",
       "4                            @Kwesidei not the whole crew                                                                    \n",
       "...                                                    ...                                                                   \n",
       "1599994  Just woke up. Having no school is the best fee...                                                                   \n",
       "1599995  TheWDB.com - Very cool to hear old Walt interv...                                                                   \n",
       "1599996  Are you ready for your MoJo Makeover? Ask me f...                                                                   \n",
       "1599997  Happy 38th Birthday to my boo of alll time!!! ...                                                                   \n",
       "1599998  happy #charitytuesday @theNSPCC @SparksCharity...                                                                   \n",
       "\n",
       "[1599999 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin1')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224c311e-6685-42b2-967d-222c19fbae82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5718fc72-40d3-482f-9018-0bdc1ca0d728",
   "metadata": {},
   "source": [
    "### 3. Rename the Column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cebc046-d39d-4a7c-bdfe-2ca2ad85fd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_names = ['target','Id','date','flag','user','text']\n",
    "data = pd.read_csv('training.1600000.processed.noemoticon.csv',names = columns_names, encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f794259e-f241-4458-b8c2-c23ebb3d5d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.groupby('target', group_keys=False).apply(lambda x: x.sample(frac=0.25, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9c623bb-1a55-47b2-8d6a-8d2b3e7b33db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aa8d77-64b0-42d8-9dcb-cbdde5dc9cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfd013f1-5336-4280-bb6c-b0683968b4df",
   "metadata": {},
   "source": [
    "### 4. Check For Null Values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f33dc6c6-96f1-41fa-ba4d-47a6a2172a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target    0\n",
       "Id        0\n",
       "date      0\n",
       "flag      0\n",
       "user      0\n",
       "text      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e0d763-f804-4995-9f8d-a6f434625e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ffa0c4c9-fb8b-4365-9378-4644cde44bc3",
   "metadata": {},
   "source": [
    "### 5. Replacing Values in the `Target` Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e494cfe7-aaa1-4d4f-b881-96cb1bf62686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'].replace({0:0,4:1},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02b09335-3bc2-4899-8e0a-2a668637730f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    200000\n",
       "1    200000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b009cd2a-4123-45d0-8078-31dabbd24514",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fa357e10-5420-4b36-8fbb-d5cdf7cac008",
   "metadata": {},
   "source": [
    "### 6. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2422202-7d01-4662-9d05-dcf7d5d6e449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Welcome\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Welcome\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Welcome\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df30d0f6-75d0-4e08-9ebf-e12b50b4606f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7651c772-35d0-4aa9-8af1-c2a0eef543b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60dff8f9-8692-44ba-b85b-23bd6fd1d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    # Initialize the PorterStemmer and stop words\n",
    "    lem=WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Remove non-alphabetic characters\n",
    "    text_cleaned = re.sub('[^a-zA-Z]', ' ', text)\n",
    "\n",
    "    # Convert to lowercase and split into words\n",
    "    words = text_cleaned.lower().split()\n",
    "\n",
    "    # Remove stop words and apply stemming\n",
    "    stemmed_words = [lem.lemmatize(word) for word in words if word not in stopwords.words('english')]\n",
    "\n",
    "    # Join the words back into a single string\n",
    "    processed_text = ' '.join(stemmed_words)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8de14ea-d67d-45c9-a8ad-6d85db581df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Stemmed_Text']=df['text'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b48b83bf-4ae8-427a-86a6-26d2687bfad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Id</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>Stemmed_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212188</th>\n",
       "      <td>0</td>\n",
       "      <td>1974671194</td>\n",
       "      <td>Sat May 30 13:36:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>simba98</td>\n",
       "      <td>@xnausikaax oh no! where did u order from? tha...</td>\n",
       "      <td>xnausikaax oh u order horrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299036</th>\n",
       "      <td>0</td>\n",
       "      <td>1997882236</td>\n",
       "      <td>Mon Jun 01 17:37:11 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Seve76</td>\n",
       "      <td>A great hard training weekend is over.  a coup...</td>\n",
       "      <td>great hard training weekend couple day rest le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475978</th>\n",
       "      <td>0</td>\n",
       "      <td>2177756662</td>\n",
       "      <td>Mon Jun 15 06:39:05 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>x__claireyy__x</td>\n",
       "      <td>Right, off to work  Only 5 hours to go until I...</td>\n",
       "      <td>right work hour go free xd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>588988</th>\n",
       "      <td>0</td>\n",
       "      <td>2216838047</td>\n",
       "      <td>Wed Jun 17 20:02:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Balasi</td>\n",
       "      <td>I am craving for japanese food</td>\n",
       "      <td>craving japanese food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138859</th>\n",
       "      <td>0</td>\n",
       "      <td>1880666283</td>\n",
       "      <td>Fri May 22 02:03:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>djrickdawson</td>\n",
       "      <td>Jean Michel Jarre concert tomorrow  gotta work...</td>\n",
       "      <td>jean michel jarre concert tomorrow gotta work ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        target          Id                          date      flag  \\\n",
       "212188       0  1974671194  Sat May 30 13:36:31 PDT 2009  NO_QUERY   \n",
       "299036       0  1997882236  Mon Jun 01 17:37:11 PDT 2009  NO_QUERY   \n",
       "475978       0  2177756662  Mon Jun 15 06:39:05 PDT 2009  NO_QUERY   \n",
       "588988       0  2216838047  Wed Jun 17 20:02:12 PDT 2009  NO_QUERY   \n",
       "138859       0  1880666283  Fri May 22 02:03:31 PDT 2009  NO_QUERY   \n",
       "\n",
       "                  user                                               text  \\\n",
       "212188         simba98  @xnausikaax oh no! where did u order from? tha...   \n",
       "299036          Seve76  A great hard training weekend is over.  a coup...   \n",
       "475978  x__claireyy__x  Right, off to work  Only 5 hours to go until I...   \n",
       "588988          Balasi                    I am craving for japanese food    \n",
       "138859    djrickdawson  Jean Michel Jarre concert tomorrow  gotta work...   \n",
       "\n",
       "                                             Stemmed_Text  \n",
       "212188                     xnausikaax oh u order horrible  \n",
       "299036  great hard training weekend couple day rest le...  \n",
       "475978                         right work hour go free xd  \n",
       "588988                              craving japanese food  \n",
       "138859  jean michel jarre concert tomorrow gotta work ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36414415-2860-490c-9d7f-2b66312b57ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb65557f-d163-4529-a20a-0a0a11f4490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df['Stemmed_Text'].values\n",
    "y=df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90da9e10-c628-4c66-a487-ceac313c0dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xnausikaax oh u order horrible'\n",
      " 'great hard training weekend couple day rest let lot computer time put'\n",
      " 'right work hour go free xd' ... 'amyeve glad like'\n",
      " 'donniewahlberg love wake morn amp see tweetin ure lol luvs ya gonna great day'\n",
      " 'piece work week stand betweeen end nd year']\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e3b7b22-6619-4180-871c-9c39b1fc4ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d911546e-d325-46bd-ab62-d845d57b3e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35c16d47-61c0-4822-898d-f805b49d6bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72987c3e-603a-445a-8460-dfcb6636848d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320000,)\n",
      "(80000,)\n",
      "(320000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80000,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytrain.shape)\n",
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c08a3b-9b9e-4ef7-8c68-a7dfa31aea6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6c2267a-ae45-4401-99e8-0144beb72c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7536a2f-ba20-4e54-ba97-f049e409c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vect=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dd7b733-35ce-4789-89c0-9b3f4d58e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=vect.fit_transform(xtrain)\n",
    "xtest=vect.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de6dd9e4-c7ce-485d-8c06-d31bd0fb6711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 33181)\t0.42122610845123787\n",
      "  (0, 133797)\t0.6238533587517132\n",
      "  (0, 73485)\t0.3922175221562081\n",
      "  (0, 173416)\t0.5287163394929993\n",
      "  (1, 159531)\t0.45540362861342765\n",
      "  (1, 173979)\t0.17997530537877518\n",
      "  (1, 116896)\t0.20703829801440152\n",
      "  (1, 9702)\t0.26631459555093334\n",
      "  (1, 146761)\t0.3039411635693178\n",
      "  (1, 20244)\t0.39322258983748715\n",
      "  (1, 125423)\t0.3572563072090752\n",
      "  (1, 84147)\t0.521336550359119\n",
      "  (2, 43606)\t0.5418912072379292\n",
      "  (2, 55862)\t0.3077507877303229\n",
      "  (2, 164407)\t0.38868081146428385\n",
      "  (2, 34652)\t0.514231868953075\n",
      "  (2, 20673)\t0.44287264977878094\n",
      "  (3, 168782)\t0.47081240350843917\n",
      "  (3, 53319)\t0.3241106193809267\n",
      "  (3, 105208)\t0.3313198766092873\n",
      "  (3, 86733)\t0.7506764459277546\n",
      "  (4, 19506)\t0.8223314475966161\n",
      "  (4, 188760)\t0.40797403964624823\n",
      "  (4, 64361)\t0.39664615625059996\n",
      "  (5, 141260)\t0.5433003954756446\n",
      "  :\t:\n",
      "  (319996, 171824)\t0.34532551588966576\n",
      "  (319996, 53288)\t0.3493841674942259\n",
      "  (319996, 53229)\t0.3147373199776172\n",
      "  (319996, 158735)\t0.31353555475197953\n",
      "  (319996, 39932)\t0.20299341206877397\n",
      "  (319996, 162535)\t0.2499597818458189\n",
      "  (319997, 126096)\t0.5741720587588731\n",
      "  (319997, 97478)\t0.46247134345953284\n",
      "  (319997, 98372)\t0.46247134345953284\n",
      "  (319997, 63868)\t0.2650880787409719\n",
      "  (319997, 117532)\t0.27568127410196236\n",
      "  (319997, 62800)\t0.1744621850676248\n",
      "  (319997, 98817)\t0.1786586439816054\n",
      "  (319997, 173979)\t0.18422578654762092\n",
      "  (319998, 86040)\t0.5516462047269612\n",
      "  (319998, 86612)\t0.5516462047269612\n",
      "  (319998, 106863)\t0.45380911321604\n",
      "  (319998, 188839)\t0.26087717899000884\n",
      "  (319998, 185782)\t0.2729274384934133\n",
      "  (319998, 178187)\t0.20708435281882\n",
      "  (319999, 10493)\t0.6436347010611105\n",
      "  (319999, 67047)\t0.6174938974523505\n",
      "  (319999, 70413)\t0.29787775327067223\n",
      "  (319999, 125322)\t0.2415190610159327\n",
      "  (319999, 169635)\t0.23952671139453313\n"
     ]
    }
   ],
   "source": [
    "print(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8808ff7f-6299-4f4a-b219-d8f68e5686f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b08c5e94-f919-47fc-9f2e-f753882b4d0d",
   "metadata": {},
   "source": [
    "### 7. Model Building  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7c85522-e7af-4f47-9158-b08256abdeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4d4012b-3253-45c4-bd24-8218d76b2bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=LogisticRegression(max_iter=1000)\n",
    "model.fit(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ef0ef7a-f495-4d28-93c6-d4dc3f91783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain_pred=model.predict(xtrain)\n",
    "training_data_accuracy=accuracy_score(ytrain,xtrain_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9a4626ec-ea5a-413d-8f3f-3c6f5af478c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy score of training data is 0.820784375\n"
     ]
    }
   ],
   "source": [
    "print('The Accuracy score of training data is', training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a7a28c-0ece-4292-bc23-7e21d8eb932e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1ad6f674-86f7-4601-8530-298e47e03e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_pred=model.predict(xtest)\n",
    "testing_data_accuracy=accuracy_score(ytest,xtest_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cfeb2b28-251f-49cb-af0e-7da9fb346faa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy score of training data is 0.7732625\n"
     ]
    }
   ],
   "source": [
    "print('The Accuracy score of training data is', testing_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9c75df-4b56-4edb-8a44-b3a6b6b37ea5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "673ade7f-d666-4b4a-a2a8-481b170ebb8c",
   "metadata": {},
   "source": [
    "### 8. Saving the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "761712bd-16af-473c-b1ad-ab9fbee264f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8862ae6-52ba-4850-b9ba-d565c22160b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Model 1.0.joblib']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model, 'Model 1.0.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44c7e405-2e1c-4500-b833-fa1b4266fc14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.joblib']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the vectorizer for later use\n",
    "joblib.dump(vect, 'tfidf_vectorizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce224f00-a981-4cb8-926a-7edbd6b9b674",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24118224-719d-44c8-88d7-726a6686fb1d",
   "metadata": {},
   "source": [
    "### 9. Check for a Tweet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c3acc219-02d7-4d1e-99c3-f7c8f3dee0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load('Model 1.0.joblib')\n",
    "tfidf_vectorizer = joblib.load('tfidf_vectorizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf4a7f1-b1a6-4c93-93ed-1b443c0ff97e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9485b152-84a9-480e-b4df-73fba5478645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict the sentiment of a tweet\n",
    "def predict_tweet_sentiment(tweet):\n",
    "    # Preprocess the tweet (lowercase)\n",
    "    tweet = tweet.lower()  # Basic preprocessing\n",
    "    \n",
    "    # Vectorization using TF-IDF\n",
    "    tweet_vectorized = tfidf_vectorizer.transform([tweet])  # Transform the tweet to the TF-IDF vector\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(tweet_vectorized)  # Pass the vectorized tweet to the model\n",
    "    return 'Positive' if prediction[0] == 1 else 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bc9e2291-e274-4c08-980a-79db02972331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: \"I love this product! It's amazing.\" -> Sentiment: Positive\n"
     ]
    }
   ],
   "source": [
    "# Example usage 1\n",
    "tweet = \"I love this product! It's amazing.\"\n",
    "sentiment = predict_tweet_sentiment(tweet)\n",
    "print(f'Tweet: \"{tweet}\" -> Sentiment: {sentiment}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828f7a79-5b70-4c4a-9dc6-afeaf8c7111f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a236407-21e6-4c32-8e58-e00daed8f116",
   "metadata": {},
   "source": [
    "# Example Tweet Link\n",
    "You can view the tweet [here](https://x.com/sudi0ne/status/1716739204011405583)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8822ebf-d09b-445e-9283-352efd64b74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: \"Samsung follows the same path as Apple, the path of charts from Excel This is not a good path Without numbers and crazy specifications there will be no success\" ->>>>>>>>>  `Sentiment` : Negative\n"
     ]
    }
   ],
   "source": [
    "tweet = \"Samsung follows the same path as Apple, the path of charts from Excel This is not a good path Without numbers and crazy specifications there will be no success\"\n",
    "sentiment = predict_tweet_sentiment(tweet)\n",
    "print(f'Tweet: \"{tweet}\" ->>>>>>>>>  `Sentiment` : {sentiment}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2eb106-26f8-42db-bcc1-a4ea171f4833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
